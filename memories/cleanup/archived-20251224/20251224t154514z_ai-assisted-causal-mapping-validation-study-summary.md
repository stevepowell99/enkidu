---
title: AI-assisted causal mapping â€” validation study (summary)
id: ea5bff5f0651a9c4ae0b1a3d
created: 2025-12-24T15:45:14Z
tags: causal-mapping, ai, evaluation
importance: 1
source: sources_ingest
source_ref: memories/sources/verbatim/f1df281b5e2d_ai-assisted-causal-mapping-summary-validation.md
original_path: 000 Articles/AI-assisted causal mapping -- Summary (validation).md


source_set_context: our publications on causal mapping and summaries of them
---

- Goal: test whether an AI language model can identify and label causal claims in qualitative interviews, and compare with human expert coding; focus on extraction validity, not causal inference.
- Framing: causal mapping vs systems modelling; edges indicate evidence that X influences Y; output is an evidence repository with provenance, not a predictive model.
- Naive coding: uses an undifferentiated causal influence; no effect sizes or polarity; aims to answer where a causal claim exists and what influences what.
- Data: QuIP evaluation (2019) of an Agriculture and Nutrition Programme; hand-coded by humans; criterion study; validation subset: 3 sources, 163 statements, ~15 pages.
- Extraction procedure: Causal Map app with GPT-4.0, temperature 0; produce exhaustive, transparent list with verbatim quotes; exclusions: ignore hypotheticals; output per claim includes statement ID, quote, influence factor, consequence factor.
- Validation variants: open coding (radical zero-shot) with no codebook; and codebook-assisted (closed-ish) with a partial top-label codebook.
- Metrics & takeaway: precision results (variant 1: 84% of links perfect 8/8; variant 2: 87% of links perfect 8/8); recall is proxy; AI mappings broadly resemble human maps at top level; small sample; not for high-stakes adjudication; label consistency varies.
- Source: 000 Articles/AI-assisted causal mapping -- Summary (validation).md

Why: Summarizes the aims, methods, and findings of an AI-assisted causal-mapping validation study for quick recall and filing.
