---
id: 078c3c02711bed42438d620d
title: Ideas: causal-mapping minimalism, AI limits, history & data-viz
created: 2025-12-24T20:48:50Z
tags: ideas, social-science, causation, methods, ai, dataviz, philosophy, history, books
importance: 2
source: sources_ingest
source_ref: memories/sources/verbatim/d2f0e823d68a_20251224t204302z-ideas-part24.md
original_path: pasted/20251224t204302z_ideas_part24.md
source_set: ideas

source_set_context: things i am learning like social science etc
---

- Perspective bias: we tend to diminish attention to past and future; every era/culture is large and worth comparing to understand feelings of precarity.
- Minimal causal-mapping stance: represent causes as simple boxes (propositions/factors) and undifferentiated arrows; let labels do the explanatory work rather than encoding necessity/sufficiency, strengths, or specialized arrow types.
- Skepticism about “hidden system levers”: if a lever reliably works it becomes part of the system — question narrow boundary definitions that claim secret high-impact levers.
- Method preference: increase explicit human participation in designing coding methods; decrease implicit/hidden human roles in execution.
- Short checklist of AI failure modes: offensive outputs, unpredictable internal state dependence, weak/circumventable ethics, hallucinations, stale training data, arithmetic and reliability issues, overconfidence and inconsistent behaviour.
- Data visualization has two roles: (1) a scientific discovery tool and (2) a way to communicate a Gestalt (the moment parts cohere); attention and perceptual organization matter.
- Philosophical note: treat variables defined in terms of other variables as practically real (can become psychologically primitive) rather than getting stuck on ontological debates.

Key quotes:
> "We diminish the attention we pay to the past and also to the future... The only parts of history we are supposed to care about, unless we are geeks, are the ones that have some brand attached to them."

> "If we're just talking about the pace of change, that's the extraordinary thing about an exponential curve: it always looks the same and to be accelerating the same wherever you are on it, if you re-adjust the axes to the local context."

Source: pasted/20251224t204302z_ideas_part24.md

Why: Captures methodological preferences (minimal causal maps, participatory coding), practical warnings about AI, and recurring intellectual themes worth recalling for future projects.
