---
id: 9560656f34ee2cfb5f43b4cd
title: Ideas: AI governance proposals & curated article highlights (Dec 2023)
created: 2025-12-24T20:47:31Z
tags: ideas, AI, regulation, training-data, content-credentials, provenance, systems-change, articles, highlights
importance: 1
source: sources_ingest
source_ref: memories/sources/verbatim/5d8263055af4_20251224t204302z-ideas-part18.md
original_path: pasted/20251224t204302z_ideas_part18.md
source_set: ideas

source_set_context: things i am learning like social science etc
---

- Treat AI like an ongoing "arms race": require continuous patching, detectability of generated content, and structured collaboration between AI developers and distribution channels.
- Training-data transparency and scrutiny: mandate disclosure of training data and ban use of PII, content designed to produce hateful outputs, and content tied to biological/chemical weapons or enabling capabilities in those domains.
- Governance & oversight measures: fund independent researcher access and monitoring; require Know-Your-Customer (KYC)-style procedures for AI purchasers/providers.
- Content provenance & distribution: require content credentials on all distribution channels; push phone/camera makers to adopt C2PA provenance standards and automate digital signatures for authentic content.
- This note contains a curated list of related articles (systems change, process-tracing, media moral panics, AI tech pieces, nuclear safety story highlights) collected for follow-up reading.

Key quotes:
- "The report said events that could trigger an atmospheric release of radioactive waste at the plant included explosions and air crashes." (Sellafield article highlight)
- "An estimated 1.7 million died under Khmer Rouge rule." (BBC highlight on Kissinger/Cambodia)

Source: pasted/20251224t204302z_ideas_part18.md

Why: Collects practical AI-governance proposals (data transparency, provenance, oversight) and related curated readings for future policy or research follow-up.
