---
title: 20251224t204302z-ideas-part06
created: 2025-12-24T20:44:20Z
tags: source, verbatim
importance: 0
source: sources_ingest
source_id: a61bd9a82d81
original_path: pasted/20251224t204302z_ideas_part06.md
source_set: ideas

source_set_context: things i am learning like social science etc
---

- This relationship between NP-complete problems is central to the “P versus NP” conjecture, the most famous unsolved problem in computer science, which seeks to define the limits of computation in mathematical terms. (The informal version: if P equals NP, we could quickly compute the true answer to almost any question we wanted, as long as we knew how to describe what we wanted to find and could easily recognize it once we saw it, much like a finished jigsaw puzzle. The vast majority of computer scientists believe that P does not equal NP.) The P versus NP problem also helps draw an informal line between tractable (“[easy](http://blog.computationalcomplexity.org/2005/03/favorite-theorems-efficient.html)”) and intractable (“hard”) computational procedures.
      - SETH addresses an open question about the hardness of NP-complete problems under worst-case conditions: What happens as the number of variables in a SAT formula gets larger and larger? SETH’s answer is given in razor-sharp terms: You shall never do better than exhaustive search. According to Scott Aaronson, a computational complexity expert at MIT, “it’s like ‘P not equal to NP’ on turbochargers.”
      - The Upside of Impossible
      - Paradoxically, it’s SETH’s sharpness about what cannot be done that makes it so useful to complexity researchers. By assuming that certain problems are computationally intractable under precise constraints, researchers can make airtight inferences about the properties of other problems, even ones that look unrelated at first. This technique, combined with another called reduction (which can translate one question into the mathematical language of another), is a powerful way for complexity theorists to examine the features of problems. According to Impagliazzo, SETH’s precision compared to that of other hardness conjectures (such as P not equal to NP) is a bit like the difference between a scalpel and a club. “We’re trying to [use SETH to] form more delicate connections between problems,” he said.
      - SETH speaks directly about the hardness of NP-complete problems, but some surprising reductions have connected it to important problems in the complexity class P—the territory of so-called easy or efficiently solvable problems. One such P-class problem is edit distance, which computes the lowest number of operations (or edits) required to transform one sequence of symbols into another. For instance, the edit distance between book and back is 2, because one can be turned into the other with two edits: Swap the first o for an a, and the second o for a c.
      - Indyk and Bačkurs were able to prove a connection between the complexity of edit distance and that of k-SAT, a version of SAT that researchers often use in reductions. K-SAT is “the canonical NP-complete problem,” Aaronson said, which meant that Indyk could use SETH, and its pessimistic assumptions about k-SAT’s hardness, to make inferences about the hardness of the edit-distance problem.
      - The result was striking because edit distance, while theoretically an easy problem in the complexity class P, would take perhaps 1,000 years to run when applied to real-world tasks like comparing genomes, where the number of symbols is in the billions (as opposed to book and back). Discovering a more efficient algorithm for edit distance would have major implications for bioinformatics, which currently relies on approximations and shortcuts to deal with edit distance. But if SETH is true—which Indyk and Bačkurs’ proof assumes—then there is no hope of ever finding a substantially better algorithm.
      - The key word, of course, is “if.” Indyk readily concedes that their result is not an unconditional impossibility proof, which is “the holy grail of theoretical computer science,” he said. “Unfortunately, we are very, very far from proving anything like that. As a result, we do the next best thing.”
      - Indyk also wryly admits that he was “on the receiving end of several tweets” regarding the Globe’s overstatement of his and Bačkurs’ achievement. “A more accurate way of phrasing it would be that [our result] is strong evidence that the edit-distance problem doesn’t have a more efficient algorithm than the one we already have. But people might vary in their interpretation of that evidence.”
      - Ryan Williams certainly interprets it differently. “It’s a remarkable connection they made, but I have a different interpretation,” he said. He flips the problem around: “If I want to refute SETH, I just have to solve edit distance faster.” And not even by a margin that would make a practical dent in how genomes get sequenced. If Williams or anyone else can prove the existence of an edit-distance algorithm that runs even moderately faster than normal, SETH is history.
      - And while Williams is one of the only experts trying to refute SETH, it’s not a heretical position to take. “I think it’s entirely possible,” Aaronson said. Williams is making progress: His latest research refutes another hardness assumption closely related to SETH. (He is preparing the work for publication.) If refuting SETH is scaling Everest, this latest result is like arriving at base camp.
      - Even though falsifying SETH “could be the result of the decade,” in Aaronson’s words, to hear Williams tell it, SETH’s truth or falsity is not the point. “It’s almost like the truth value isn’t so relevant to me while I’m working,” he said. What he means is that the scalpel of SETH is double-edged: Most researchers like to prove results by assuming that SETH is true, but Williams gets more leverage by assuming it is false. “For me it seems to be a good working hypothesis,” he said. “As long as I believe it’s false, I seem to be able to make lots of progress.”
      - Williams’ attempts at disproving SETH have borne considerable fruit. For example, in October [he will present](http://www.cs.cmu.edu/~venkatg/focs15/schedule/program.html) [a new algorithm](http://arxiv.org/abs/1507.05106) for solving the “nearest neighbors” problem. The advance grew out of a failed attempt to disprove SETH. Two years ago, he took a tactic that he had used to try and refute SETH and applied it to the “all-pairs shortest paths” problem, a classic optimization task “taught in every undergraduate computer science curriculum,” he said. [His new algorithm](http://arxiv.org/abs/1312.6680) improved on computational strategies that hadn’t significantly changed since the 1960s. And before that, another abortive approach led Williams to derive [a breakthrough proof](http://web.stanford.edu/~rrwill/acc-lbs.pdf) in a related domain of computer science called circuit complexity. [Lance Fortnow](http://lance.fortnow.com/), a complexity theorist and chairman of the Georgia Institute of Technology’s School of Computer Science, called Williams’ proof “the best progress in circuit lower bounds in nearly a quarter century.”
      - The Map and the Territory
      - In addition to these peripheral benefits, attacking SETH head-on helps researchers like Williams make progress in one of the central tasks of theoretical computer science: mapping the territory. Just as we know more about the surface of the moon than we do about the depths of our own oceans, algorithms are all around us, and yet they seem to defy researchers’ efforts to understand their properties. “In general, I think we underestimate the power of algorithms and overestimate our own ability to find them,” Williams said. Whether SETH is true or false, what matters is the ability to use it as a tool to map what Williams calls the topography of computational complexity.
      - Indyk agrees. While he didn’t prove that edit distance is impossible to solve more efficiently, he did prove that this theoretically tractable problem is fundamentally connected to the intrinsic hardness of NP-complete problems. The work is like discovering a mysterious isthmus connecting two landmasses that had previously been thought to be oceans apart. Why does this strange connection exist? What does it tell us about the contours of the mathematical coastline that defines hard problems?
      - “P versus NP and SETH are ultimately asking about the same thing, just quantifying it differently,” Aaronson said. “We want to know, How much better can we do than blindly searching for the answers to these very hard computational problems? Is there a quicker, cleverer way to mathematical truth, or not? How close can we get?” The difference between solving the mysteries of SETH and those of P versus NP, Aaronson adds, may be significant in degree, but not in kind. “What would be the implications of discovering one extraterrestrial civilization versus a thousand?” he mused. “One finding is more staggering than the other, but they’re both monumental.”
      - [Original story](https://www.quantamagazine.org/20150929-edit-distance-computational-complexity/) reprinted with permission from [Quanta Magazine](https://www.quantamagazine.org/), an editorially independent publication of the [Simons Foundation](https://www.simonsfoundation.org/) whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
    - [Go Back to Top. Skip To: Start of Article.](http://www.wired.com/2015/10/major-advance-reveals-limits-computation/#start-of-content)
    - Quantum ‘spookiness’ passes toughest test yetSourceURL: http://www.nature.com/news/quantum-spookiness-passes-toughest-test-yet-1.18255
    - Nature|News
    - Sharing
      - [](https://en.wikipedia.org/wiki/Kolmogorov_complexity#)
    - Quantum ‘spookiness’ passes toughest test yet
    - Experiment plugs loopholes in previous demonstrations of 'action at a distance', against Einstein's objections — and could make data encryption safer.
    - [Zeeya Merali](http://www.nature.com/news/quantum-spookiness-passes-toughest-test-yet-1.18255#auth-1)
    - 27 August 2015
    - Article tools
      - PDF
      - Rights & Permissions
    - CERN
    - John Bell devised a test to show that nature does not 'hide variables' as Einstein had proposed. Physicists have now conducted a virtually unassailable version of Bell's test.
    - It’s a bad day both for Albert Einstein and for hackers. The most rigorous test of quantum theory ever carried out has confirmed that the ‘spooky action at a distance’ that the German physicist famously hated — in which manipulating one object instantaneously seems to affect another, far away one — is an inherent part of the quantum world.
    - The experiment, performed in the Netherlands, could be the final nail in the coffin for models of the atomic world that are more intuitive than standard quantum mechanics, say some physicists. It could also enable quantum engineers to develop a new suite of ultrasecure cryptographic devices.
    - “From a fundamental point of view, this is truly history-making,” says Nicolas Gisin, a quantum physicist at the University of Geneva in Switzerland.
    - Einstein’s annoyance
    - Related stories
      - [Quantum physics: What is really real?](http://www.nature.com/doifinder/10.1038/521278a)
      - [Physics: Bell’s theorem still reverberates](http://www.nature.com/doifinder/10.1038/510467a)
      - [Cosmic light could close quantum-weirdness loophole](http://www.nature.com/doifinder/10.1038/nature.2014.14771)[More related stories](http://www.nature.com/news/quantum-spookiness-passes-toughest-test-yet-1.18255#related-links)
    - The Bell test and spooky entanglement
      - [Follow @NatureNews](https://twitter.com/NatureNews)
    - References
      - Bell, J. S. Physics 1, 195–200 (1964).
    - Show context
      - Hensen, B. et al. Preprint at [http://arxiv.org/abs/1508.05949](http://arxiv.org/abs/1508.05949) (2015).
    - Show context
