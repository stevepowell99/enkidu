---
title: eval2025
created: 2025-12-24T15:10:06Z
tags: source, verbatim
importance: 0
source: sources_ingest
source_id: 231943c06ffe
original_path: 000 Articles/!!eval2025.md
---

- # **An AI-powered workflow for collecting and understanding stories at scale**

  # **Abstract**

  This paper presents an AI-assisted causal mapping pipeline for gathering and analysing stakeholder perspectives at scale. Evidence relevant to constructing a program theory, as well as evidence for the causal influences flowing through it, are both collected at the same time, without the evaluator needing to possess a prior theory. The method uses an AI interviewer to conduct interviews, automated coding to identify causal claims in the transcripts, and causal mapping to synthesise and visualise results. The authors tested this approach by interviewing participants about problems facing the USA. Results indicate the method can efficiently collect and process qualitative data, producing useful causal maps that capture respondents' views. The paper discusses the potential of this approach for evaluation, enabling rapid, large-scale qualitative analysis. It also notes limitations and ethical concerns, emphasising the need for human oversight and verification.

  # **Motivation and background**

  To evaluate a program, the evaluator can use Contribution Analysis (CA) [@mayneMakingCausalClaims2012]. We start with a program logic or Theory of Change (ToC), consisting of possible pathways from interventions to outcomes, and collect existing or new evidence for each link. However evaluators can often not assume that the ToC underpinning a program aligns with the realities on the ground, or they may uncover outcomes not anticipated in the original program design - see Koleros & Mayne [(2019)](https://www.zotero.org/google-docs/?CY0JAD). We have argued [(Powell, Copestake, et al., 2023](https://www.zotero.org/google-docs/?v391Z7), p. 114) for a generalisation of CA in which evidence relevant to constructing a program theory, as well as evidence for the causal influences flowing through it, are both collected at the same time, without the evaluator (necessarily) having a prior theory. In this sense, following Mayne, “program theory” need not be something that any person necessarily possessed or articulated at the time, but is something which can be approximated and improved during the evaluation process.

  (Re-)constructing program theory empirically in this way is an essentially open-ended, qualitative problem. Closed data collection methods are not suitable because we cannot measure what we do not yet know. Open-ended, qualitative methods to (re-)construct a theory are notoriously time-consuming and are usually heavily influenced by researcher positionality [(Copestake et al., 2019)](https://www.zotero.org/google-docs/?RXnwkL).

  [Powell, Copestake, et al (2023](https://www.zotero.org/google-docs/?A2dhGE), p. 108) present this task as gathering and synthesising evidence about "what influenced what", evidence which is simultaneously about theory or structure and contribution. Each piece of evidence may be of differing quality and reliability and about different sections of a longer pathway, or multiple interlocking pathways, and may come from different sources who see and value different things. 

  ## Causal mapping as part of the solution

  One way to meet the challenge of simultaneously assessing theory and contribution is by using causal mapping [(Ackermann and Eden, 2004; Axelrod, 1976; Eden et al., 1992; Hodgkinson and Clarkson, n.d.; Laukkanen and Wang, 2016; Powell, Copestake, et al., 2023)](https://www.zotero.org/google-docs/?sgDmH1) - the collection, coding and visualisation of interconnected causal claims. Causal mapping can be seen as unifying visual and text-based approaches and involves identifying causal claims within a set of texts. Each piece of text which contains information that a source S claims that X causally influences Y is coded: represented as a directed link or arrow in a network, connecting node X to node Y. Along with each link, the information about the origin of this claim, the source S, is also noted. Causal mapping provides a structured approach of synthesising (some of) the meaning of large quantities of text, from interviews or documents, providing a relatively generic way to extract and uncover emerging meaning. We can see causal mapping as a form of qualitative data analysis in which the fundamental act of coding requires creating not a single tag or theme but an ordered pair of tags, the cause and the effect. 

  This evidence may A) be collected systematically from relatively homogenous sources, as in QuIP [(Copestake et al., 2019)](https://www.zotero.org/google-docs/?7sT01L), or B) be a mix, consisting, for example, of some systematic interviews, some official data, and some reports from a monitoring system. In this article, we focus only on Option A.

  If we broaden our view beyond any specific results chain, causal mapping can also be useful to evaluators who need to know how groups of people see the world, what these views of the world have in common and what distinguishes them, perhaps to make informed recommendations for program improvement [(Copestake et al., 2019)](https://www.zotero.org/google-docs/?MD5e0R). 

  We sometimes use the phrase “causal landscapes” to describe the object of causal maps, to emphasise that we are most interested in the contents and layout of the broader world in which stakeholders understand themselves to be living. 

  We believe that causal mapping should carefully distinguish between evidence for a causal link and the causal link itself. While causal mapping can help the evaluator to identify, code and synthesise the evidence for causal connections, the evaluative judgement about whether one thing causally influences another is left to the evaluator [@betterevaluationCausalMapping2024]. 

  Constructing causal maps by gathering and coding individual interview transcripts (rather than by consensus in groups [@ackermannGettingStartedCognitive2004; @barbrook-johnsonBayesianBeliefNetworks2022] can be a challenge for evaluators due to the complexity of the task and the resource-intensive and researcher-dependent nature of human-led coding. The use of AI-driven tools is rapidly increasing among evaluators [(Bohni Nielsen et al., 2024)](https://www.zotero.org/google-docs/?fbPJnn). AI can facilitate tasks by, for example, enabling virtual platforms to engage hard-to-reach populations or augment human capabilities by processing large datasets, auto-coding qualitative inputs, or optimising data analysis [(Eloundou et al., 2023)](https://www.zotero.org/google-docs/?arnIon).

  ### Using causal mapping to gather evidence about structure/theory and contribution simultaneously

  Our suggestion comprises the following steps (following Tasks 1-3 according to [@mathisInductiveThematicAnalysis2024] provide an end-to-end workflow with a single, general large language model (LLM) interviewer similar to ours and a suggestion for automated analysis, but their analysis approach is a global one involving the identification of themes across all transcripts and then identifying whether each theme is present in each transcript. 

  ## Step 1: Using an AI interviewer to gather causal information at scale

  Data gathering with AI-powered chatbots has become popular in various businesses and industries. Chatbots have been used to gather customer data, feedback and to provide automated responses to frequently asked questions [@yuenChatbotMarket20222022] and in evaluation for tasks like gathering feedback [@nielsenDisruptingEvaluationEmerging2023] or conducting “laddering” interviews to investigate respondents’ values [@rietzLadderbotConversationalAgent2022]. [@chopraConductingQualitativeInterviews2023], suggesting that chat automations can be a valid and effective way to gather open-ended information from respondents. However, their approach involves a sophisticated set-up with multiple bots which are hard-coded into a team to monitor and steer the progress of the interview. Our experience has found hard-coding can be effective but difficult to adjust for different kinds of interviews. In this study, we leave the control of the interview, as well as developing and delivering the responses and new questions, all to a single automated interviewer. [@geieckeConversationsScaleRobust2024] present an approach similar to our own, using a single LLM agent to conduct useful social research interviews.

  The term “chatbot” for this kind of broader use of genAI to conduct natural-seeming conversations seems no longer appropriate, and we prefer the term “AI interviewer”. 

  In the world of machine learning, a clear distinction can be made between supervised and unsupervised approaches [(Ziulu et al., 2024)](https://www.zotero.org/google-docs/?HRDIxL). Using genAI to conduct interviews and code texts blurs this boundary. In our case, we developed our semi-generic instructions for interviewing, giving the AI instructions on how to behave, and how to make follow-up questions based on the interview objectives. Once the data collection is done, we create a separate genAI prompt to code causal links as a trial-and-error process, monitoring the quality of the coding post-hoc. We did not have an explicitly stated ground truth about exactly how the interview should look or which causal claims were “really” present within each text passage or how their causes and effects should be labelled, as we believe neither of these questions have a definitive answer; rather, we monitored AI’s responses coding post-hoc, iterating the prompt over many cycles to improve its performance. "Prompt engineering" [@ferrettiHackingPromptInnovative2023] like this can be considered a kind of supervision because it steers the AI’s responses in a desired way. 

  Once the prompt was finalised, the interview AI was left to conduct interviews without further supervision. This prompt can remain broadly the same across different studies. However, the response of the AI can be highly sensitive to small differences in the "prompt" and other settings [@jangConsistencyAnalysisChatGPT2023]. Small adjustments made for specific studies, such as adjusting the instructions to focus better on research objectives, remain a vital point of human intervention.

  ## Step 2: using automated causal mapping to code causal information at scale

  Making sense of texts by assigning codes or topics to text sections (or even entire documents) can be called thematic analysis [(Braun et al., 2020; Braun and Clarke, 2006)](https://www.zotero.org/google-docs/?GIotH1) or Qualitative Data Analysis (QDA) [@laceyQualitativeDataAnalysis2001]. Approaches to automating this process have moved on from topic modelling [@cintronIntegratingBigData2021] based on counting and clustering the words in the texts [(Blei et al., 2003)](https://www.zotero.org/google-docs/?SqO8yS) to sentiment analysis [@royTheresMuchNot2021] and procedures which use LLMs to capture the meaning of longer sections of text [(Sia et al., 2020; Ziulu et al., 2024)](https://www.zotero.org/google-docs/?pNVsGu).

  Our task is more specific: identifying not just general meanings but specifically causal relationships. Coding texts by hand for causal mapping has until recently been time-consuming work for trained analysts. Thus it has remained a relatively niche approach. The limited sample size means it is difficult to make generalisations or comparisons between subgroups or across timepoints, reducing its utility for program monitoring. 

  Earlier language models [(Devlin et al., 2019)](https://www.zotero.org/google-docs/?pprHAR) and other machine-based techniques have been used to identify causal relationships expressed in text [@dunietzAnnotatingAutomaticallyTagging2018] - for an overview see [@yangSurveyExtractionCausal2022]. However, these were highly specialised procedures which required "training" the models. The advent of large language models and genAI makes this process much easier because we can rely on the model’s inherent understanding of causality and directly ask the model to “identify causal claims” rather than having to define exactly what this means.

  The task of identifying causal claims is simpler than the broader problem of identifying themes in general, as with thematic analysis, because the task “identify all the causal claims in this text” is more specific than “identify all the themes in this text”. The latter approach would require a pre-reading of the text to know what kind of themes we might want to look for, which would leave the AI with too much freedom to make judgments for us and would also be more likely to expose any underlying model biases.

  Evaluators [@daviesEvaluatingThematicCoding2023; @ferrettiHackingPromptInnovative2023] have recently been demonstrating the possibilities of AI in evaluation, for example with asking AIs for summaries or global syntheses of texts including interviews (see [Wachinger et al., 2024](https://www.zotero.org/google-docs/?wqYft5) and [Mason and Montrosse‐Moorhead, 2023)](https://www.zotero.org/google-docs/?Wayudc). It is even possible to ask an AI to synthesise the main causal links within a text and produce a diagram directly [@grahamUsingChatGPTForesight2023]. However, when doing this, evaluators have to take care not to leave fundamental evaluative decisions such as “within this text, what are the most important claims” to the LLM. Evaluators should be wary of transferring the responsibility for making evaluative judgements to an unknown third party, the “black box” of the AI [(Choudhary et al., 2022)](https://www.zotero.org/google-docs/?uk8wAq). One way to navigate this complexity is to systematically break down larger, weakly-specified tasks into multiple, smaller, better-specified tasks and also to clearly distinguish where AI adds value and where human insight is needed.

  In this sense, we prefer approaches which use the power of genAI more transparently, as a low-level coding assistant in the tradition of QDA or thematic analysis who follows detailed instructions, leaving the evaluator with the responsibility of making evaluative judgements. This involves establishing coding guidelines designed to extract causal information from the documents with little guidance. 

  Jalali and Akhavan [(2024)](https://www.zotero.org/google-docs/?E3sw6N) use one such approach. They first instruct the AI to construct a codebook (a list of salient causal factors) based on the whole text and then use this codebook to identify and code links. While they report good results, we see this as still leaving too much freedom for the AI to make its own global “judgement” based on processing the whole text about what are the salient factors and therefore also being more exposed to bias inherent in the AI’s “worldview”. 

  There are different ways to create factor labels for the influence and consequence factors making up of each causal link. They may be:

  - specified in advance deductively in the form of a codebook 
    - based on pre-existing theory;
    - based on a preliminary assessment of the text to be coded, as with Jalali and Akhavan;
  - according to a codebook which is developed iteratively during coding [@laukkanenComparativeCauseMapping1994] and QuIP [(Copestake et al., 2019)](https://www.zotero.org/google-docs/?4lGkNn);
  - created “In vivo” in whatever form is most suited to each coding. This means that there will be many different labels for the causes and effects, many of which are likely to overlap in meaning. We call this approach to causal coding “radical zero-shot”: no codebook or examples are provided, and there is no mechanism to ensure consistent labels across the dataset. This coding procedure maximises granularity but means that to build synthesis maps, it will be necessary to subsequently, retrospectively, cluster labels into sets with similar meaning and provide appropriate labels for the clusters. This is the approach we prefer and use in this paper. 

  As with creating the instruction (“prompt”) for the AI interviewer, developing an instruction to identify causal links was a trial-and-error process, involving monitoring the quality of the coding post-hoc, making adjustments post-hoc as we analysed the quality of the coding and identified errors or gaps. 

  ## Step 3: using automated causal mapping to help answer evaluation questions

  The extensive causal mapping literature provides many examples of its use to answer evaluation questions (see [Powell, Copestake, et al., 2023](https://www.zotero.org/google-docs/?NywxMq), p. 110), for example:

  - Getting an overview of respondents’ "causal landscape". This can be useful for orientation or for particular tasks like triaging masses of information to identify key outcomes and possible causal pathways when planning an Outcome Harvesting [@wilson-grauOutcomeHarvesting2012] or Process Tracing [@befaniProcessTracingBayesian2017] project. 
  - Weighing up evidence about contribution: in particular, tracing back and comparing the possibly multiple contributory causes of an important outcome or consequence [@goertzTaleTwoCultures2006], or examining effects of causes. 
  - Reporting key metrics of the causal network, for example, to reveal which factors are most central in the whole network or to identify feedback loops.
  - Asking whether the empirical ToC matches the plan [(Powell, Larquemin, et al., 2023](https://www.zotero.org/google-docs/?OBOgWM), p. 7). 
  - Making comparisons between groups or across timepoints. 

  We have integrated the research questions into the method steps below and set out more detailed criteria for evaluating the research questions within the results section.

  # **Method: the “AI-assisted causal mapping pipeline”**

  We present a procedure which harnesses the power of AI to facilitate and augment evaluation practice [(Eloundou et al., 2023)](https://www.zotero.org/google-docs/?G198td) in three ways: firstly to carry out large numbers of automated, qualitative, online interviews, secondly to automatically code the transcripts and thirdly, to present overview causal maps.

  ## Step 1: Conducting the chat interviews 

  This paper presents results from a proof-of-concept analogue study. We employed online workers as respondents, recruited via Amazon’s MTurk platform [(Shank, 2016)](https://www.zotero.org/google-docs/?dLRh2d). We decided to investigate respondents’ ideas about problems facing the USA, as this generic theme was likely to elicit opinions from randomly chosen participants. This unsophisticated way of recruiting respondents means that the results cannot be generalised to a wider population in this case.

  We had no specific evaluative questions in mind; We aimed to demonstrate a method which can be easily adapted to a specific research question. 

  A short semi-structured interview guideline was designed on the theme of "What are the important current problems facing the USA and what are the (immediate and underlying) reasons for those problems?". We aimed to construct an overall collective “ToC” around problems in the USA. As it does not encompass a specific intervention this theory is not an example of a program theory. 

  This interview guideline was implemented via an online interview "AI interviewer" called "Qualia", which uses the OpenAI Application Programming Interface (API) to control the AI’s behaviour. Qualia is designed to elicit stories from multiple individual respondents, in an AI-driven chat format. Individual respondents are sent a link to an interview on a specific topic and, after consenting, are greeted by the interviewer. Rather than following a set list of questions, the interviewer is instructed to adapt its responses and follow-up questions depending on the respondents' answers, circling back to link responses and asking for more information as appropriate, focusing on the interview's objective mentioned above. These behaviours are based on the instructions written by the authors. 

  The respondents, who had the level of “Master” on Amazon's MTurk service, each completed an interview. The Amazon workers were given up to 19 minutes to complete the interview. 

  We repeated this interview at three different timepoints in September, October and November 2023, inviting approximately N=50 respondents each time. The data from the three timepoints was pooled.

  **The Research Question for Step 1 is: can an automated interview bot successfully gather causal information at scale?**

  ## Step 2: Coding the interviews

  ### Step 2a: Constructing a guideline

  Once the interviews were completed, we wrote instructions to guide the qualitative causal coding of the transcripts, in a radical zero-shot style: without giving a codebook or any examples. The assistant was told not to give a summary or overview but to list *each and every causal link or chain* of causal links and to ignore hypothetical connections (for example, “if we had X we would get Z”). We told the AI to produce codes or labels following this template: 'general concept; specific concept'. We gave no examples, but expected the AI to produce labels like: “economic stress; no money to pay bills”. We call the combination of both parts a (factor) label.

  The assistant was told also to provide a corresponding verbatim quote for each causal chain, to ensure that every claim could be verified. Codings without a quote which matched the original text were subsequently rejected, thus reducing the potential for “hallucination”. 

  ### Step 2b: Coding

  The final instructions were human-readable and could have been given to a human assistant. Instead, we gave these instructions to the online app "Causal Map", which used the GPT-4 OpenAI API. As the transcripts were quite long (each around a page of A4 in length), each was submitted separately. The “temperature” (the amount of “creativity”) was set to zero to improve reproducibility. The Causal Map app managed the housekeeping of keeping track of combining the instructions with the transcripts, watching out for any failed requests and repeating them, saving the causal links identified by the AI, etc. 

  ### Step 2c: Clustering

  The coding procedure resulted in many different labels for the causes and effects, many of which overlap in meaning. Even the general concepts (e.g. “economic stress”) were quite varied. The procedure for clustering these labels (including both the general and specific parts of the label) into common groups with their labels was a three-step process based on assigning to each of the original labels an embedding. An embedding is a numerical encoding of the meaning of each label [(Chen et al., 2023)](https://www.zotero.org/google-docs/?XMlguD) in the form of a point in a space, such that two labels with similar meaning are close in this space. For any two such vectors, a measure cosine similarity can be calculated representing the approximate similarity in meaning between the labels which they encode:

  1. **Inductive clustering**. First, we grouped the labels into clusters of similar labels using the hclust() function from the stats package of base R [@rcoreteamLanguageEnvironmentStatistical2015]. 
  2. **Labelling.** We then asked an AI to find distinct labels for each cluster. We also manually inspected these labels with regard to the original labels within each cluster and adjusted some of them. 
  3. **Deductive clustering.** We then discarded the original clustering, created embeddings for the new labels, and formed a new set of clusters, one for each of the new labels, assigning each original label to one of the new labels, the one to which it was most similar, providing the similarity was at least higher than a given threshold. This additional deductive step ensures that each member of each new cluster is sufficiently close in meaning to the new cluster label, rather than just to the other members of the cluster. 

  After each sub-step, we checked the AI’s results to ensure that the instructions were being followed correctly and, if they weren't, the instructions were tweaked or rewritten and tested again to ensure quality and consistency.

  **The Research Question for Step 2 is: can automated causal mapping successfully code causal information at scale?**

  ## Step 3: Making useful syntheses of causal mapping data to answer evaluation questions

  Standard filters (details on request) can be applied to the resulting dataset of causal claims to create overview causal maps as a qualitative summary of the respondents' "causal landscapes". The primary aim is to construct a simple map with a not-overwhelming number of links and factors which captures a large percentage of the information given by the respondents. In addition, network metrics like centrality can be used to identify the factors which are most central within the network. To weigh up the evidence for the contributions made to a specific factor, we can list the evidence (the specific quotes from specific respondents) for direct and indirect links leading to it. 

  **The Research Question for Step 3 is: can automated causal mapping help answer evaluation questions?**

  # **Results**

  The sub-headings within each question form our criteria for answering that question.

  ## Question 1: can an AI interviewer gather causal information at scale?

  ### Efficiency

  As we were still experimenting with the process, it took us around 8 hours to write, test, deploy and monitor the interviews. 

  We spent around $40 on API fees, including both tests and real interviews. The time and cost involved were significantly less than what it would have taken for humans to create an interview guideline and interview the same number of participants.

  ### Validity 

  This is a difficult question to answer fully. However, in the interview prompt, we instruct the AI to summarise the conversation at the end of the interview and ask the respondent to verify its accuracy. We can use these answers to make a rough assessment of how valid the original summaries were: if the interviewee expresses no dissatisfaction, we can assume that the interviewer successfully elicited valid information.

  The final section of all 163 interviews was analysed. We classified each interview into 3 groups:

  1. No summary provided;
  2. The respondent explicitly expressed dissatisfaction and/or asked for changes in the summary;
  3. The respondent finished the interview and did not explicitly express dissatisfaction nor ask for changes in the summary.

  78.5% of the respondents (**group 3**) didn’t ask for changes in the summary, implying at least no dissatisfaction with what the AI produced (128 out of 163 interviews). Only in 7 interviews (4.29%) did the interviewee ask the AI to change or correct something in the summary, and/or the respondent explicitly expressed dissatisfaction (**group 2**). Of these, three then explicitly expressed satisfaction with the revised summary offered by the AI. The other 25 interviews (15.3%) were not summarised (**group 1**), mainly due to the participants breaking off before the end of the interview. 

  We used a much simpler architecture to manage the interview process than Chopra and Haaland [(2023)](https://www.zotero.org/google-docs/?plc9gZ), however, our interviews were much shorter than theirs (their average interview length was about 30 minutes), raising the question of whether longer interviews might need more elaborate management architecture. 

  ## Question 2: Can automated causal mapping code causal information at scale?

  ### Efficiency

  It took around 5 hours to write and test the coding instructions and validate the results. 

  The cost of using the API was around $20.

  ### Recall

  Recall can be defined as the extent to which the AI finds “all” the causal links [@resnikEvaluationNLPSystems2010]. 

  We made a separate assessment of the number of links “really” present within each interview, a “ground truth” of 1154 links. In comparison, the automated coding identified 1024 links, or 89%. However this is before assessing which of those codings were correct: the precision of the links, as follows. 

  ### Precision 

  Precision can be defined as the proportion of the identified links which were accurate/correct [@resnikEvaluationNLPSystems2010]. To define “correct” we used the following informal criteria, which were assessed for each link by the second author:

  1. The cause and effect in each link correctly name phenomena which are named in the text;
  2. The coding represents an actual causal claim within the text (rather than, for example, merely events listed in sequence);
  3. The coding represents a factual claim rather than a wish or hypothetical statement.
  4. The coding is in the correct direction (cause to effect).

  We gave each causal link a 0-2 score on the four criteria of precision as detailed in the Supplementary Material. 65% of the links had a perfect score, and 72% dropped only one point (a “not sure” on only one criterion). The errors we identified seem to take place approximately at random, except that there were more errors with causal claims which human analysts themselves judged to be difficult to code. 

  ### A more systematic assessment of the coding process on a real-life dataset had similar results and is currently in press (redacted).

  ## Question 3: can automated causal mapping help answer evaluation questions?

  ### Can an overall causal map be generated which includes much of the information?

  The map in Figure 1 is filtered to show only the top 11 factors (in terms of the number of respondents mentioning them); links mentioned by only one source are also removed, meaning many less frequently mentioned factors and links are not shown. 

  We introduce a measure which we call **coding coverage**: given any map based on any recoding or filtering of the original data, what percentage of the original codings are included? There are balances to be struck: a map with more factors will usually have higher coverage but will be harder to understand and less useful. More homogeneity in sample and theme usually mean higher coverage. Very granular clustering will mean lower coverage or a larger map. 

  The first result can be seen in Figure 1. This map contains only 11 factors but covers 42% of the raw causal claims. 

  **Insert Figure 1 around here.**

  Most (113 out of 136) sources have contributed at least some citations to this summary map. The numbers on the factors and links (and the sizes of the factors and the widths of the links) represent the number of sources mentioning each. Factors with darker backgrounds have proportionately more incoming than outgoing links: they have greater “outcome-ness”. 

  At this coarse level of “granularity”, many of the factors are bundles of cause-effect stories, as shown by the “self-loops” such as the 10 sources that mentioned links between different environment/climate change issues. 

  In this map, it is mostly not possible to distinguish between constituent factors with different valence or sentiment. For example, “military strengthening” and “military weakening” are two codes which have been included under “International conflict”. Indeed they are not so far from one another in the overall space of embeddings, something which is quite hard to understand from a positivistic, Cartesian point of view but which is perhaps more familiar to those more used to thinking in terms of "themes" than in terms of “variables”.

  ### Face validity

  Does the overall causal map present a plausible picture of the most important factors and how they influence one another (in the opinion of respondents)? Yes, even in the absence of a particular research focus, this causal map has a lot to tell us about the causal worlds of the respondents. 

  “It’s the economy, stupid”: economic stress is mentioned by the largest number of sources and is central to most of the narratives. Covid-19 appears as a pure driver of economic stress. 

  ### Ability to answer other evaluation questions

  Regarding the differences between timepoints, there were significant differences for several of the links. For example, of the five sources that mentioned the link from Political conflict to International conflict overall, all of them were from the third time-point, which is unsurprising considering the situation in Israel/Palestine at that timepoint. 

  In this analogue study, we did not have any additional information e.g. about the sociodemographic characteristics of the respondents which would have enabled us to look at differences between subgroups. 

  In a more realistic evaluation context, it would be possible to further investigate narratives about the causes and effects of specific factors of interest. 

  # **Discussion** 

  **Question for Step 1 -** **can an AI interviewer successfully gather causal information at scale?****:** Our AI interviewer was able to conduct multiple interviews with no researcher intervention at a low cost, reproducing the results of [@chopraConductingQualitativeInterviews2023; @anderssonTheoryChangeSustainable2024]. The interview transcripts read quite naturally and the process seems to have been acceptable to the interviewees. 

  **Question for Step 2 -** **can automated causal mapping successfully code causal information?****:** Automated coding was able to identify causal claims made by respondents. The coding was noisy, with 35% dropping at least one quality point, but with no evidence of *systematic* errors*.* This level of precision is adequate for sketching out “causal landscapes” but would not be for high-stakes evaluations without additional manual correction. The accuracy can also be substantially improved by getting the AI to revise its work, (see redacted). This procedure still involves the researchers making significant high-level decisions in the formulation of the coding instructions as well as, before analysis, in clustering similar factor labels into groups. We believe this coding approach using genAI represents a significant improvement over the more hard-coded approaches for identifying causal relationships expressed in text [@dunietzAnnotatingAutomaticallyTagging2018][Yang et al., 2022)](https://www.zotero.org/google-docs/?ForqTu), and provides a more detailed, section-by-section coding which relies less on using AI as a black box to identify themes for initial coding [@jalaliIntegratingAILanguage2024] or to identify a global map [@grahamUsingChatGPTForesight2023].

  **Question for Step 3 -** **can automated causal mapping help answer evaluation questions?****:** An overview map was produced which included over 40% of the causal claims identified within the transcripts, using just 11 relatively broad factor labels. 

  The most central factor with the highest number of citations was Economic stress, which is a plausible result, with plausible connections to other factors. 

  We can use the map to identify and weigh up the evidence for contributions from and to individual factors. For example, the major contributions to Economic stress are Government policy and Covid-19, as well as “self-loops” mentioned by 46 sources, i.e. where one aspect of Economic stress was seen as causing another. 

  All such results depend on the (not automated) decisions made during the clustering process: how many clusters to use, whether to intervene in labelling, etc. This situation is closely parallel to decisions facing a statistician who has to identify variables for, say, structural equation modelling [@goertzSocialScienceConcepts2020]. 

  Comparison of citation frequency across timepoints was able to show that some links were mentioned significantly more than others, illustrating how this kind of map could be used to explore changes in systems (or in mental models of systems) over time. 

  ## Caveats

  ### Ethics, bias and validity

  This kind of AI processing is not suitable for dealing with sensitive data because information from the interviews passes to OpenAI’s servers, even though it is no longer used for training models [@openaiAnnouncingGPT4oAPI2024]. 

  [@headLargeLanguageModel2023] and [@reidVisionEquitableAI2023] raise concerns about bias and the importance of equity in AI applications for evaluation, which have led to questions about the validity of AI-generated findings [@azzamArtificialIntelligenceValidity2023]. The way the AI sees the world, the salient features it identifies, the words it uses to identify them, and its understanding of causation are certainly wrapped up in a hegemonic worldview [(Bender et al., 2021)](https://www.zotero.org/google-docs/?7Mxaw6). Those groups most likely to be disadvantaged by this worldview are approximately the same who have least say in how these technologies are developed and employed. 

  AI is developing quickly: new models and techniques become available every month. However, we believe that any tools which genuinely add to knowledge should use procedures which are broken down into workflows consisting of simple individual steps so that humans can understand and check what is happening.

  ### Interviewing

  Researchers should carefully consider whether the interview subject matter is compatible with this kind of approach. For example, the AI may miss subtle cues or struggle to provide appropriate support to respondents expressing distress [@chopraConductingQualitativeInterviews2023; @rayChatGPTComprehensiveReview2023]. We recommend that interview guidelines are tested and refined by human interviewers before being automated. No automated interview can substitute for the contextual information which a human evaluator can gain by talking directly to a respondent, ideally face-to-face and in a relevant context. 

  There is likely to be a differential response rate in this kind of interview: some people are less likely to respond to an AI-driven interview than others, and this propensity may not be random.

  ### Causal mapping

  Causal mapping is not at all suited for estimating the strength of causal effects: it can reveal the *strength of the evidence* for the influence of X on Y but this is not to be confused with the *strength of the effect* itself. There can be strong evidence for a weak link and vice-versa. 

  ### Autocoding

  The work of the AI coder and clustering algorithms are not error-free. The coding of individual high-stakes causal links should be checked. In particular, there is a danger of accepting inaccurate results which look plausible.

  This approach does not nurture substantive, large-scale theory-building of the kind expected, for example in grounded theory [@glaserDiscoveryGroundedTheory1967]. However, it can do smaller-scale theory-building in the sense of capturing theories implicit in individuals’ responses. 

  This pipeline relieves researchers of much of the work involved in coding but it is not fully autonomous. The human evaluator is responsible for applying the techniques in a trustworthy way and for drawing valid conclusions.

  ## Potential

  **Qualitative approach:** These procedures approach the stakeholder stories as far as possible without preconceived templates, to remain open to emerging and unexpected changes in respondents’ causal landscapes. 

  **Scalability and reach:** The AI’s ability to communicate in many languages presents an opportunity to reach more places and people, subject to internet access and the AI’s fluency in less common languages, and to include representative samples of populations.

  The interview and coding processes are machine-driven and use zero temperature, so this approach should be mostly reproducible. Reproducibility opens the possibility of comparing results across groups, places and timepoints. 

  The low cost of coding large amounts of information means that it is much easier to develop, compare and discard hypotheses and coding approaches, something which qualitative researchers have previously been understandably reluctant to do.

  **Qualitative causality:** These procedures have the potential to help evaluators answer evaluation questions which are often causal in nature, like: understanding stakeholders' mental models; judging whether "their" ToC matches "ours"; investigating “how things work” for different subgroups of stakeholders; tracing impact from mentions of "our" intervention to outcomes of interest; triaging the key outcomes in stakeholders’ perspectives. 

  In summary, this kind of semi-automated pipeline opens up possibilities for monitoring, evaluation and social research which were unimaginable just three years ago and are well suited to today’s challenging, complex problems like climate change and political and social polarisation. Previously, only quantitative research claimed to produce generalisable knowledge about social phenomena validly and at scale, by turning meaning into numbers. Now perhaps qualitative research will eclipse quantitative research by bypassing quantification and dealing with meaning directly, in somewhat generalisable ways. 

  ## Further work

  We have tried to demonstrate a semi-automated workflow with which evaluators can capture stakeholders’ emergent views of the *structure* of a problem or program at the same time as capturing their beliefs about the *contributions* made to factors of interest by other factors. We have presented this approach via a proxy application but have since applied it in real-life research. Many challenges remain, from improving the behaviour of the automated interviewer through improving the accuracy of the causal coding process to dealing better with valence (for example distinguishing between “employment”, “employment issues” and “unemployment”). Perhaps most urgently needed are ways to better understand and counter how LLMs may reproduce hegemonic worldviews [@reidVisionEquitableAI2023].

  # **References**

  [@ackermannGettingStartedCognitive2004]

  [@amazoninc.SimplifiedMastersQualifications2016]

  [@axelrodAnalysisCognitiveMaps1976]

  [@azzamArtificialIntelligenceValidity2023]

  [@barbrook-johnsonBayesianBeliefNetworks2022]

  [@befaniProcessTracingBayesian2017]

  [@benderDangersStochasticParrots2021]

  [@bleiLatentDirichletAllocation2003]

  [@bohninielsenEvaluationEraArtificial2024]

  [Braun V and Clarke V (2006) Using thematic analysis in psychology. *Qual. Res. Psychol.* 3(2): 77–101.](https://www.zotero.org/google-docs/?FV9BPQ)

  [@braunOnlineSurveyQualitative2020]

  [@bruceEmergingTechnologyEvaluation2024]

  [@lawrenceGlobalPolycrisisCausal2024]

  [@chenSubSentenceEncoderContrastive2023]

  [@chopraConductingQualitativeInterviews2023]

  [@choudharyInterpretationBlackBox2022]

  [@cintronIntegratingBigData2021]

  [@copelandReasonableSocialWelfare1951]

  [@copestakeAttributingDevelopmentImpact2019]

  [@daviesEvaluatingThematicCoding2023]

  [@devlinBERTPretrainingDeep2019]

  [@dunietzAnnotatingAutomaticallyTagging2018]

  [@dunietzBECauSECorpus202017]

  [@edenAnalysisCauseMaps1992]

  [@eloundouGPTsAreGPTs2023]

  [@ferrettiHackingPromptInnovative2023]

  [@geieckeConversationsScaleRobust2024]

  [@glaserDiscoveryGroundedTheory1967]

  [@goertzSocialScienceConcepts2020]

  [@goertzTaleTwoCultures2006]

  [@grahamUsingChatGPTForesight2023]

  [@headLargeLanguageModel2023]

  [Hodgkinson GP and Clarkson GP (n.d.) What Have We Learned from Almost 30 Years of Research on Causal Mapping?: 4.](https://www.zotero.org/google-docs/?FV9BPQ)

  [@jalaliIntegratingAILanguage2024]

  [@jangConsistencyAnalysisChatGPT2023]

  [@jiangLargeLanguageModel2023]

  [@kolerosUsingActorbasedTheories2019]

  [@laceyQualitativeDataAnalysis2001]

  [@laukkanenComparativeCauseMapping1994]

  [@laukkanenComparativeCausalMapping2016]

  [@masonEditorsNotes2023]

  [@mayneMakingCausalClaims2012]

  [@mayneUsefulTheoryChange2015]

  [@nielsenDisruptingEvaluationEmerging2023]

  [@openaiAnnouncingGPT4oAPI2024]

  [@powellDoesOurTheory2023]

  [@powellDoesOurTheory2023]

  [@aidleapContributionVsAttribution2015]

  [@rayChatGPTComprehensiveReview2023]

  [@reidVisionEquitableAI2023]

  [@resnikEvaluationNLPSystems2010]

  [@rietzLadderbotConversationalAgent2022]

  [@roryhooperSemiautomatedApproachPolicyrelevant2023]

  [@royTheresMuchNot2021]

  [Shank DB (2016) Using Crowdsourcing Websites for Sociological Research: The Case of Amazon Mechanical Turk. *Am. Sociol.* 47(1): 47–55.](https://www.zotero.org/google-docs/?FV9BPQ)

  [@siaTiredTopicModels2020]

  [@wachingerPromptsPearlsImperfections2024]

  [@wilson-grauOutcomeHarvesting2012]

  [@yangSurveyExtractionCausal2022]

  [@yuenChatbotMarket20222022]

  [@ziuluExtractingMeaningTextual2024]

  

  # **List of figure captions**

  Figure 1: A high-level overview causal map. Causal factors are automatically clustered as described in the Supplementary Material. 

