---
title: 20251224t204302z-ideas-part23
created: 2025-12-24T20:48:20Z
tags: source, verbatim
importance: 0
source: sources_ingest
source_id: 56904947e428
original_path: pasted/20251224t204302z_ideas_part23.md
source_set: ideas

source_set_context: things i am learning like social science etc
---

- gab er wie ein römischer Held dem Arzt Erlaubnis, dem Schmerz ein Ende zu bereiten. — location: [6055](kindle://book?action=open&asin=B074XKKPM2&location=6055) ^ref-22577
      - Dann hatte man ihnen die Dienstboten genommen — location: [6076](kindle://book?action=open&asin=B074XKKPM2&location=6076) ^ref-57852
      - jetzt erst zwang man den Juden zum erstenmal seit Hunderten Jahren wieder eine Gemeinsamkeit auf, die sie längst nicht mehr empfunden, die seit Ägypten immer wiederkehrende Gemeinsamkeit der Austreibung. — location: [6120](kindle://book?action=open&asin=B074XKKPM2&location=6120) ^ref-6246
      - Und so starrten sie sich an auf der Flucht mit brennenden Augen – warum ich? Warum du? — location: [6124](kindle://book?action=open&asin=B074XKKPM2&location=6124) ^ref-11969
      - Ich hatte in jenen Monaten London verlassen und mich auf das Land nach Bath zurückgezogen. — location: [6141](kindle://book?action=open&asin=B074XKKPM2&location=6141) ^ref-22625
      - Vergiß! sagte ich mir. Flüchte dich, flüchte dich in dein innerstes Dickicht, in deine Arbeit, in das, wo du nur dein atmendes Ich bist, nicht Staatsbürger, nicht Objekt dieses infernalischen Spiels, — location: [6165](kindle://book?action=open&asin=B074XKKPM2&location=6165) ^ref-24380
      - ich die Absicht hatte, eine zweite Ehe zu schließen, — location: [6187](kindle://book?action=open&asin=B074XKKPM2&location=6187) ^ref-50124
      - Für den nächsten Tag sollte die Trauung angesetzt werden; er nahm seine Feder und begann mit schönen runden Lettern unsere Namen in sein Buch zu schreiben. In diesem Augenblick – es muß etwa elf Uhr gewesen sein – wurde die Tür des Nebenzimmers aufgerissen. Ein junger Beamter stürmte herein und zog sich im Gehen den Rock an. »Die Deutschen sind in Polen eingefallen. Das ist der Krieg!« rief — location: [6191](kindle://book?action=open&asin=B074XKKPM2&location=6191) ^ref-3903
- Ideas-key
  - what is the geography and geology of human experience around something like post-traumatic growth? in a way that might help identify constructs or gestalts within that domain which might help people articulate their thoughts or help clinicians with theorybuilding or diagnosis at an individual or group level?
    - one way is to take the cloud of information about differences in extent of growth between individuals and reduce it to two or three linear dimension which as best as possible mark out that space, make it measurable. 
    - or you could start from their testimonies around the developments in them after traumatic events, problems and how they are maintained, talking also about the idea of growth, and try to identify some common causal factors within their stories and common links between those factors. 
      - you don't know initially which of these these factors will be more about triggers or aspects of suffering or something else entirely.  
  - nuance and high stakes decisions
    - Agreeing with most of the above, and a special applause for Florencia and Tom's piece. I like the way they address the process rather than the type of data or analysis.
    - Coming here from a modest acquaintance with psychotherapy effectiveness research, where I’ve observed similar debates between quantitative and qualitative schools. I think it’s unfair to claim this problem with nuance is solely the fault of quantitative researchers for being insufficiently nuanced. For decades — at least 30 or 40 years — it’s been widely accepted that the key question isn’t simply “what works?” but rather “what works, for whom, in what circumstances, and why?” And I'm assuming that any colleagues with their salt in the quant evaluation of development effectiveness think the same.
    - So in therapy research, they acknowledge the complex interplay of variables, such as the pathology, the context of the treatment, the person delivering it, and other factors. No-one cares (any more) about the main effect, like overall CBT is the best or psychodynamic is bullshit.
    - To be fair, the basic concept of presenting scientific results as a main effect with nuanced caveats — like interaction effects and subgroup analyses — is a brilliant move. Maybe it's just how our brains work. It allows scientific findings to be communicated to the public in a digestible way. For instance, people might remember that CBT is effective for anxiety but then qualify that with considerations like comorbidities, age group, or cognitive functioning. You can't remember or work with hundreds of interaction effects and in this kind of research there are really very many of them.
    - This method simplifies communication: starting with a general takeaway before diving into specific contexts and probabilities of success. While this is an oversimplification built on numerous assumptions, it is still an effective way to derive meaning from data. Of course, in some datasets, you might in fact find no main effect but significant interactions — therapy that doesn’t work overall but is effective for specific groups and possibly harmful to others. This complexity is harder to remember and to base policies on. And even experts can struggle with higher-order interactions.
    - This challenge isn’t unique to quantitative results. Qualitative research faces similar barriers: how do you communicate nuanced findings to a policymaker who demands simple bullet points, wherever they come from? If the response is “it depends,” the message often fails to resonate. Therefore, claiming that qualitative research inherently occupies the “nuance corner” or just communicates better is misleading.
    - I'm guessing that plenty of quant people must have uttered a wry grunt when Paulson and Tilly came up with “what works for whom, in what circumstances.” They really did not invent this way of thinking.
    - The real issue, as Tom and others have already said, surely isn’t the type of data or analysis but how much we organise our world in terms of high-stakes questions and binary, all-or-nothing propositions.
    - For example, the Ofsted scandal in the UK highlighted the dangers of reducing school performance to oversimplified ratings like pass or fail. It took tragic events, like teachers’ suicides, to prompt reforms. Yet, history repeats itself. Months later, the incoming Labour government boasts about publishing league tables for hospitals — another flawed reduction of complex evaluative judgements into a single metric, whether the league table comes from something “soft and fuzzy” like QCA or hierarchical card sorting — or some other favourite qualitative approach.
    - It is the reductionism, whether from qualitative or quantitative approaches, that is problematic. The problem is how much we expect information to be aggregated as it moves up the chain of decision-making. By the time it reaches the highest levels, it’s reduced to a couple of traffic light icons for a single minister. That oversimplified output then gets propagated back down as blunt directives, such as in the extreme case, “Close this school” or Put this hospital into special measures.” I'm caricaturing here and this isn't something I know a lot about, but common sense would surely go with more distributed, localized, and adaptive management approaches - being more trusting of teachers, headteachers, nurses doctors, local education and health authorities, empowering them with the resources and support to make informed decisions within their contexts. And as often, the optimum is somewhere in between, between the big picture and the local context.
  - one difference between an evaluator and a (qualitative) researcher: evaluators don't get to set their own questions
  - special advantages of causal QDA through the eyes of AI
    - > We often see evaluators and other researchers using AI for tasks like "list the main themes in this document" or even "list the main themes in this collection of documents".
> To be clear: we've all done it. there are times when it can be a useful time-saver. 
> But the trouble with that is 
> - it's massively sensitive to what one means by a theme. What *do you *mean by "theme"? 
> - you can improve your prompt massively simply by narrowing the universe: 
> - "Identify the main kinds of relationship issues mentioned"
> - The natural conclusion of this narrowing-down is reducing the generation problem to a categorisation problem. Categorisation is probably taking things too far, because you lose the advantage of any kind of identification of unexpected things. 
> Wouldn't it be great if you could just have a generic instruction like "make sense of this document already. Just tell me what's going on, but not only as a summary, but also as a report which is to some extent representative of the different contributions from different sources or sections, *and *in such a way that it's somehow intersubjectively verifiable ?!?!
> There *is* such an instruction: it's called causal mapping. 
> The chances of two independent coders achieving somewhat similar results are much bigger with this reformulation. This is anecdotal, I don't have a reference for it. 
> There are two issues - chunk size and intersubjective verifiability.
> Ensemble agreement is the second-loop version of intersubjective verifiability.
> Rick D is going to love Workflows
    - 1. We put the question the other way round: why do thematic analysis (which is harder) when causal mapping can identify not only some of the important themes but also tell you how they influence one another?
    - 2. ... what you really want to do in the end, especially if you are doing evaluation, is find out what causes what in the eyes of your stakeholders. Identifying static themes can be interesting but often it's the causal information which helps you answer your main research and evaluation questions. Causal mapping is often a great way to cut to the chase.
    - 3. Thematic analysis is more of an art than a science. "What are the main themes here" is a very open-ended question which can (and should) be interpreted in different ways by different analysts ("positionality"). Whereas people (and GPT-4) tend understand the instruction "identify each and every section of text which says that one thing causally influences another"  quickly and easily, and they tend to agree on how to apply the rule.
    - 4. The way we do causal mapping means identifying each and every causal connection. There is less room for someone's opinion in selecting what themes are most salient. Surprisingly, we can get good results without even a codebook of suggested themes aka causal factors, let alone bothering to train the AI or give it examples.
    - 5. This means that the steps from your initial research idea all the way up to (but not including) your final analyses can be quite easily automated in a transparent way. You can train an army of analysts to the coding for you manually, or you can press the AI button, or a combination of both, and either way you will get pretty similar results. There isn't so much room for the opinion of your analysts, whether human or robot,  at any point in the pipeline.
    - Of course causal mapping is not free of bias (or positionality) due to human analysts' or AI-analysts' "world-views". It just leaves less room for those biases than more general thematic coding.
    - And of course, there are times when general thematic analysis or some other kind of QDA is really what you need. We're just saying that causal mapping might fit your need more often than you think.
  - the balance between left and right in parliaments, is that like Levi-Strauss' binary opposites? because of game theory?
  - Bricolage and Polanyi
  - Do we live in unprecedently dangerous times?
    - > We're always taught to live in the present. It's more sexy and NOW and it's supposed to be somehow spiritual yet modern. It's what hot cultures do.
