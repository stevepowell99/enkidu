---
title: 20251224t204302z-ideas-part05
created: 2025-12-24T20:44:03Z
tags: source, verbatim
importance: 0
source: sources_ingest
source_id: bf084a7fda21
original_path: pasted/20251224t204302z_ideas_part05.md
source_set: ideas

source_set_context: things i am learning like social science etc
---

- [](http://www.wired.com/wp-content/uploads/images_blogs/wiredscience/2013/03/ff_collectives5_large.jpg)
      - Crowds of humans. Amanda Mustard/Corbis
      - In a lab that looks like an aircraft hangar, several miles from Princeton’s main campus, an assortment of submersibles are suspended from the ceiling. The cool air has a tang of chlorine, thanks to a 20,000-gallon water tank, 20 feet across and 8 feet deep, home to four sleek, cat-sized robots with dorsal and rear propellers that let them swim in three dimensions.
      - The robots are called Belugas, and they’re designed to test models of collective behavior. “We’re learning about mechanisms in nature that I wouldn’t have dreamed of designing,” says engineer Naomi Leonard. She plans to release pods of underwater robots to collect data on temperature, currents, pollution, and more. Her robots can also track moving gradients, avoid each other, and keep far enough apart to avoid collecting redundant data—just enough programming to unlock more complex abilities. Theoretically.
      - Today it’s not working. Three Belugas are out of the tank so Leonard’s team can tinker. The one in the water is on manual, driven by a thick gaming joystick. The controls are responsive, if leisurely, and daredevil maneuvers are out of the question.
      - Leonard has a video of the robots working together, though, and it’s much more convincing. The bots carry out missions with a feedback-controlled algorithm programmed into them, like finding the highest concentrations of oil in a simulated spill or collecting “targets” separately and then reuniting.
      - Building a successful robot swarm would show that the researchers have figured out something basic. Robot groups already exist, but most have sophisticated artificial intelligence or rely on orders from human operators or central computers. To Tamás Vicsek—the physicist who created those early flock simulations—that’s cheating. He’s trying to build quadcopters that flock like real birds, relying only on knowledge of their neighbors’ position, direction, and speed. Vicsek wants his quadcopters to chase down another drone, but so far he’s had little success. “If we just apply the simple rules developed by us and Iain, it doesn’t work,” Vicsek says. “They tend to overshoot their mark, because they do not slow down enough.”
      - Another group of researchers is trying to pilot a flock of unmanned aerial vehicles using fancy network theories—the same kind of rules that govern relationships on Facebook—to communicate, while governing the flocking behavior of the drones with a modified version of Boids, the computer animation software that helped spark the field in the first place. Yet another team is working on applying flocking behaviors to autonomous cars—one of the fundamental emergent properties of a flock is collision avoidance, and one of the most important things self-driving cars will have to be able to do is not run into people or one another.
      - So far, the Belugas’ biggest obstacle has been engineering. The robots’ responses to commands are delayed. Small asymmetries in their hulls change the way each one moves. Ultimately, dealing with that messiness might be the key to taking the study of collectives to the next level. Ever since the days of Boids, scientists have made big assumptions about how animals interact. But animals are more than models. They sense the world. They communicate. They make decisions. These are the abilities that Couzin wants to channel. “I started off with these simple units interacting to form complex patterns, and that’s fine, but real animals aren’t that simple,” Couzin says. He picks up a plastic model of a crow from his bookshelf. “Here we have a pretty complex creature. It’s getting to the point where we’ll be able to analyze the behavior of these animals in natural, three-dimensional environments.” Step one might be to put a cheap Microsoft Kinect game system into an aviary, bathing the room in infrared and mapping the space.
      - Step two would be to take the same measurements in the real world. Every crow in a murder would carry miniature sensors that record its movements, along with the chemicals in its body, the activity in its brain, and the images on its retina. Couzin could marry the behavior of the cells and neurons inside each bird with the movements of the flock. It’s a souped-up version of the locust accelerator—combine real-world models with tech to get an unprecedented look at creatures that have been studied intensively as individuals but ignored as groups. “We could then really understand how these animals gain information from each other, communicate, and make decisions,” Couzin says. He doesn’t know what he’ll find, but that’s the beauty of being part of the swarm: Even if you don’t know where you’re going, you still get there.
    - Major Advance Reveals the Limits of ComputationSourceURL: [http://www.wired.com/2015/10/major-advance-reveals-limits-computation/](http://www.wired.com/2015/10/major-advance-reveals-limits-computation/)
      - At first glance, the big news coming out of this summer’s conference on the theory of computing appeared to be something of a letdown. For more than 40 years, researchers had been trying to find a better way to compare two arbitrary strings of characters, such as the long strings of chemical letters within DNA molecules. The most widely used algorithm is slow and not all that clever: It proceeds step-by-step down the two lists, comparing values at each step. If a better method to calculate this “edit distance” could be found, researchers would be able to quickly compare full genomes or large data sets, and computer scientists would have a powerful new tool with which they could attempt to solve additional problems in the field.
      - Yet in a paper presented at the [ACM Symposium on Theory of Computing](http://acm-stoc.org/stoc2015/), two researchers from the Massachusetts Institute of Technology put [forth a mathematical proof](http://arxiv.org/abs/1412.0348) that the current best algorithm was “optimal”—in other words, that finding a more efficient way to compute edit distance was mathematically impossible. The Boston Globe celebrated the hometown researchers’ achievement with a [headline](https://www.bostonglobe.com/ideas/2015/08/10/computer-scientists-have-looked-for-solution-that-doesn-exist/tXO0qNRnbKrClfUPmavifK/story.html) that read “For 40 Years, Computer Scientists Looked for a Solution That Doesn’t Exist.”
      - But researchers aren’t quite ready to record the time of death. One significant loophole remains. The impossibility result is only true if another, famously unproven statement called the strong exponential time hypothesis (SETH) is also true. Most computational complexity researchers assume that this is the case—including [Piotr Indyk](https://people.csail.mit.edu/indyk/) and [Artūrs Bačkurs](http://www.mit.edu/~backurs/) of MIT, who published the edit-distance finding—but SETH’s validity is still an open question. This makes the article about the edit-distance problem seem like a mathematical version of the legendary report of Mark Twain’s death: greatly exaggerated.
      - The media’s confusion about edit distance reflects a murkiness in the depths of [complexity theory](http://plato.stanford.edu/entries/computational-complexity/) itself, where mathematicians and computer scientists attempt to map out what is and is [not feasible to compute](https://www.quantamagazine.org/20140812-a-grand-vision-for-the-impossible/) as though they were deep-sea explorers charting the bottom of an ocean trench. This algorithmic terrain is just as vast—and poorly understood—as the real seafloor, said [Russell Impagliazzo](http://cseweb.ucsd.edu/~russell/), a complexity theorist who first formulated the exponential-time hypothesis with [Ramamohan Paturi](https://cseweb.ucsd.edu/~paturi/) in 1999. “The analogy is a good one,” he said. “The oceans are where computational hardness is. What we’re attempting to do is use finer tools to measure the depth of the ocean in different places.”
      - [](http://www.wired.com/wp-content/uploads/2015/10/RyanWilliams_SETH.jpg)
      - Ryan Williams, a computational complexity theorist at Stanford University. Courtesy of Ryan Williams
      - According to [Ryan Williams](http://web.stanford.edu/~rrwill/), a computational complexity theorist at Stanford University, an imprecise understanding of theoretical concepts like SETH may have real-world consequences. “If a funding agency read that [Boston Globe headline] and took it to heart, then I don’t see any reason why they’d ever fund work on edit distance again,” he said. “To me, that’s a little dangerous.” Williams rejects the conclusion that a better edit-distance algorithm is impossible, since he happens to believe that SETH is false. “My stance [on SETH] is a little controversial,” he admits, “but there isn’t a consensus. It is a hypothesis, and I don’t believe it’s true.”
      - SETH is more than a mere loophole in the edit-distance problem. It embodies a number of deep connections that tie together the hardest problems in computation. The ambiguity over its truth or falsity also reveals the basic practices of theoretical computer science, in which math and logic often marshal “strong evidence,” rather than proof, of how algorithms behave at a fundamental level.
      - Whether by assuming SETH’s validity or, in Williams’ case, trying to refute it, complexity theorists are using this arcane hypothesis to explore two different versions of our universe: one in which precise answers to tough problems stay forever buried like needles within a vast computational haystack, and one in which it may be possible to speed up the search for knowledge ever so slightly.
      - How Hard Can It Be?
      - Computational complexity theory is the study of problems. Specifically, it attempts to classify how “hard” they are—that is, how efficiently a solution can be computed under realistic conditions.
      - SETH is a hardness assumption about one of the central problems in theoretical computer science: Boolean satisfiability, which is abbreviated as SAT. On its face, SAT seems simple. If you have a formula containing variables that can be set as true or false rather than as number values, is it possible to set those variables in such a way that the formula outputs “true”? Translating SAT into plain language, though, reveals its metamathematical thorniness: Essentially, it asks if a generic problem (as modeled by a logical formula) is solvable at all.
      - As far as computer scientists know, the only general-purpose method to find the correct answer to a SAT problem is to try all possible settings of the variables one by one. The amount of time that this exhaustive or “brute-force” approach takes depends on how many variables there are in the formula. As the number of variables increases, the time it takes to search through all the possibilities increases exponentially. To complexity theorists and algorithm designers, this is bad. (Or, technically speaking, hard.)
      - SETH takes this situation from bad to worse. It implies that finding a better general-purpose algorithm for SAT—even one that only improves on brute-force searching by a small amount—is impossible.
      - The computational boundaries of SAT are important because SAT is mathematically equivalent to thousands of other problems related to search and optimization. If it were possible to find one efficient, general-purpose algorithm for any of these so-called “NP-complete” problems, all the rest of them would be instantly unlocked too.
