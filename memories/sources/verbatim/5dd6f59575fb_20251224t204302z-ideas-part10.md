---
title: 20251224t204302z-ideas-part10
created: 2025-12-24T20:45:26Z
tags: source, verbatim
importance: 0
source: sources_ingest
source_id: 5dd6f59575fb
original_path: pasted/20251224t204302z_ideas_part10.md
source_set: ideas

source_set_context: things i am learning like social science etc
---

- We are pleased to inform you that your proposal for Evaluation 2017, $sessname, has been accepted for Ignite presentation at Evaluation 2017, taking place November 6-11 in Washington, DC. This e-mail has only been sent to session submitters, so please share with others as needed.
            - To accept this invitation, please follow the steps below. This acceptance can only be completed by the session submitter. In order to create the most accurate program, all sessions must be accepted by August 1.
            - 1. The session submitter should click the link below which returns back to the original abstract submission. You must be logged in to the AEA website to access this page: $sesscmsurl
            - 2. Click “Edit Session” at the top of the screen.
            - 3. Scroll to the bottom of your proposal form where you can choose to accept or decline this invitation in the new “Session Acceptance” field (above Tags) and click OK to resubmit. This field is only editable by the session submitter.
            - Exact details (including session date/time) will follow in September once all acceptances are received, however you can plan to present your ignite presentation during one of our five reserved times: Wednesday, November 8 from 4:30-6:30pm, Thursday, November 9 from 3:15-4:15, Friday, November 10 from 8:00-9:30am or 4:30-6:00pm, and Saturday, November 11 from 8:00-9:00am.
            - Registration: All accepted presenters have access to our online registration system: http://www.evaluationconference.org/p/cm/ld/fid=503. All attendees are required to register for the meeting, so register today!
            - If you have any questions regarding this email, please email [education@eval.org](mailto:education@eval.org). In accordance with the AEA Management Standards, please allow up to five business days for a response. Unfortunately, specific schedule requests that were not expressed upon initial submission will not be able to be accommodated. General Evaluation 2017 questions not specifically related to your presentation can be emailed to [info@eval.org](mailto:info@eval.org).
            - We look forward to seeing you in DC!
        - aea submission 1
        - aea submission 2
  - Zotero
    - Paasche-Orlow and Wolf - 2007 - The Causal Pathways Linking Health Literacy to Hea.pdf
      - mentioned by CP group. but it's just some guy who has a think about how things might link up.
      - derived a conceptual causal model. Results: Health literacy should be viewed as both a patient and a system phenomenon. Three dis- tinct points along a continuum of (Page 2)
      - 2007;31(Suppl (Page 2)
      - health care are suggested to be influenced by health literacy: (1) access and utilization of health care, (2) patient-provider relation- ship, and (3) self-care. Conclusions: The conceptual model organizes what has been learned to date and underscores promising areas of fu- ture inquiry and intervention. Key words: causal pathways, (Page 2)
      - nomenon?) and not the result of a crite- rion-driven process.56 The primary rea- son that the current model is not more heavily driven by empirical evidence is that relevant data are limited. Similarly, much of the literature on literacy and health has been cross-sectional, which limits attempts to determine cause and effect relationships.57 Nonetheless, there are certain rules that govern what can be (Page 6)
      - health care literacy. (Page 7)
    - Braun et al. - 2020 - The online survey as a qualitative research tool.pdf
      - such as participants’ subjective experiences, narratives, practices, positionings, and discourses (Braun & Clarke, 2013). Within the framework of what is important to the researcher, qualitative survey data capture what is important to participants, and access their language and terminology – both frequently claimed advantages of qualitative research (Frith, 2000). Yet qualitative surveys remain a relatively novel and often invisible or side-lined method (e.g., see contents in Vannette & Krosnick, 2018; Wolf et al., 2016). A very limited methodological- (Page 2)
      - qualitative research, because they lack opportunities for probing participants’ accounts or asking follow-up questions, and must therefore only generate thin and perfunctory data. Some think that qualitative surveys must be supplemented with interviews to provide data of adequate depth and richness. In a context where surveys are typically used in large-scale (quantitative or mixed methods) research, they can at first encounter appear ill suited to the small-scale and situated samples qualitative social research often centres. But this is not the case. In this paper, we aim to unsuitability (Page 3)
      - Qualitative surveys offer one thing that is fairly unique within qualitative data collection methods – a ‘wide-angle lens’ on the topic of interest (Toerien & Wilkinson, 2004) that provides the potential to capture a diversity of perspectives, experiences, or sense-making (Braun et al., 2017b). This diversity is about hearing a range of voices and sense-making, something especially useful when researching an un- or under-explored area – which all the example studies did. In Study 1, a wide-angle lens allowed EB to identify numerous unanticipated avenues for future research on (Page 4)
      - ment, and experiences of puberty and sexual development for girls and young women. This wide scope is also useful when the population of interest is large, diverse, or indeed unknown. Or when perspectives from different groups within a wider population are sought. In Study 3, which explored 87 UK-based therapists’ sense-making around social class in therapy, CM (Page 4)
      - unfunded, or time-limited research. Through design, then, online qualitative surveys can allow social researchers to hear from a larger and more diverse sample than is possible with smaller-scale studies. For qualitative researchers, the aim in hearing from multiple participants is typically about (Page 4)
      - research beyond the ‘usual suspects’ (Braun & Clarke, 2013; Terry & Braun, 2017).7 However, while qualitative surveys are positive for inclusion and participants in many ways, an obvious disadvantage is that they require literacy and risk excluding participants with limited literacy skills – though reassuring participants that they need not be concerned about correct spelling or grammar can address this to some extent (Braun & Clarke, 2013; Terry & Braun, 2017). Similarly, given the widely recognized ‘digital divide’ (Hargittai, 2011; Van Deursen & Van Dijk, 2019), online delivery risks inadvertently excluding some of the least privileged and most vulnerable groups in society. Such factors need to be considered during design. (Page 5)
      - were more appealing to potential participants than face-to-face Online qualitative surveys are ideally suited to sensitive research Clarke, 2013) – beyond sex-focused topics – because they offer a high (Page 5)
      - (Braun et al., 2017b). The ‘anonymous’ mode of responding may also mean participants feel comfortable ‘talking back’ to the researcher, expressing views on survey design, question wording or perceived researcher agenda (Braun et al., 2017b; Terry & Braun, 2017). In a ‘trolling’ culture, this is a mixed blessing, but such comments can provide useful material for reflection. One participant in Study 1, for example, (Page 7)
      - Question wording is crucial in survey research (Page 8)
      - Length is an important survey design consideration, both overall length, and the number of topic- based questions. Qualitative surveys often ask very few topic-based questions, such as four (Barrett, 2007; Frith & Gleeson, 2004, 2008) or six (Clarke, 2016, 2019); our example studies were longer, lived experience, (Page 9)
      - In our experience, all the (increasing) detail researchers are required to include as participant information can mean that participants do not read it all, or at all – but there is no easy way to navigate this. Such information cannot be left out for the sake of brevity. But some participants are likely to complete the survey without having read some or any of the participant information. The pragmatic challenge this provides12 can be partly managed by locating key completion instructions before the first (main) question. Such information might include: reassurance around spelling and grammar; encouraging use of emojis to express emotion; instructing participants if they should (Page 9)
      - even hard copy versions could be provided.) The question of sample size for qualitative surveys is not simple (Braun & Clarke, 2013 provided some ‘rules of thumb’ for student projects). Samples are usually larger than typical for qualitative studies: ranging from a lower end of 20–49 (e.g., Barrett, 2007; Clarke & Smith, 2015; Clarke & Spence, 2013; Grogan & Mechan, 2017; Grogan et al., 2018; Hayfield, 2013) to a mid-range of 60–99 (e.g., Braun et al., 2013; Clarke, 2016, 2019; Frith & Gleeson, 2004, 2008; Peel, 2010) and an upper end of well over one hundred (e.g., Jowett & Peel, 2009; Opperman et al., 2014); two mixed (but very (Page 10)
      - social meanings of and norms around hair, gender, and appearance shape the subjectivities of people with alopecia (Davey, 2019). The more structured data generated by qualitative surveys compared to – say – interviews can seduce researchers into summarizing the responses to each question and dubbing these ‘themes’. We urge users of qualitative surveys to resist any temptation to summarize responses to each question, as this typically results in an impoverished and underdeveloped qualitative analysis. We have found it most productive to treat, and work with, the data as one cohesive dataset, coding, and developing analytic patterns across the entire dataset. Although a question might direct participants to share a particular aspect of their experience (e.g., how obsessions and compulsions impact on experiences (Page 11)
    - Yoganarasimhan and Yakovetskaya - 2023 - From Feeds to Inboxes A Comparative Study of Polarisation.pdf  
      - after accounting for factors like topics, emotion, and article age. Additionally, distinct topic preferences emerge, with social issues dominating Facebook shares and lifestyle topics prevalent in emails. Contrary to expectations, political polarization of articles shared on Facebook post-2020 election  
        - did not escalate 
      - We introduce a novel approach to measuring polarization of text content that leverages   
        - generative AI models like ChatGPT, which is both scalable and cost-effective. This research contributes to the evolving intersection of Large Language Models (Page 1)
      - toward polarizing topics. Earlier research has provided some support for the idea that social media platforms promote polarized discourse through mechanisms such as homophilic network formation, echo chambers, and filter bubbles, and suggested that personalization algorithms can amplify these effects (Shin and Kadiyala, 2022; Allcott et al., 2020; Barber´a et al., 2015; Cinelli et al., 2021; Levy, 2021; Pariser, 2011; Persily and Tucker, 2020; Sunstein, 2018). On the other hand, some emerging research has questioned this narrative (Bail et al., 2018; Boxell et al., 2017; Eady et al., 2019; Gentzkow and Shapiro, 2011). For instance, some early work shows that users’ exposure to political news on Facebook is primarily driven by the content shared by their friends rather than the algorithm used to determine users’ news feeds (Bakshy et al., 2015). In this paper, we examine one specific aspect of this issue – is the content seeded on social media (Facebook) systematically more polarized than that shared via more personal channels (email) after controlling for a variety of article features such as the content and topics in the article? (Page 2)
